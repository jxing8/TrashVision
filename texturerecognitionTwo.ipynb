{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"texturerecognitionTwo.ipynb","provenance":[{"file_id":"1W6DI5WeP8ko6DNaIdZpT-hgB5di9_U8O","timestamp":1574872551803}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JsH69sBEVU7h","colab_type":"code","outputId":"de44bb50-438a-4139-e4ac-6394709ebcb5","executionInfo":{"status":"ok","timestamp":1574969405024,"user_tz":480,"elapsed":23020,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Lf4XhZrLFxv","colab_type":"code","colab":{}},"source":["!unzip -q drive/'My Drive'/dataset-original.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-IQewQhBOfA","colab_type":"code","outputId":"509ef868-5cfc-49a5-f343-87e1f7457905","executionInfo":{"status":"ok","timestamp":1574969480965,"user_tz":480,"elapsed":98925,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}},"colab":{"base_uri":"https://localhost:8080/","height":439}},"source":["!mkdir dataset-validation\n","!mkdir dataset-validation/cardboard\n","!mkdir dataset-validation/glass\n","!mkdir dataset-validation/paper\n","!mkdir dataset-validation/plastic\n","!mkdir dataset-validation/metal\n","!mkdir dataset-validation/trash\n","!ls\n","!ls dataset-original/trash"],"execution_count":3,"outputs":[{"output_type":"stream","text":["dataset-original  dataset-validation  drive  __MACOSX  sample_data\n","trash100.jpg  trash121.jpg  trash18.jpg  trash39.jpg  trash5.jpg   trash80.jpg\n","trash101.jpg  trash122.jpg  trash19.jpg  trash3.jpg   trash60.jpg  trash81.jpg\n","trash102.jpg  trash123.jpg  trash1.jpg\t trash40.jpg  trash61.jpg  trash82.jpg\n","trash103.jpg  trash124.jpg  trash20.jpg  trash41.jpg  trash62.jpg  trash83.jpg\n","trash104.jpg  trash125.jpg  trash21.jpg  trash42.jpg  trash63.jpg  trash84.jpg\n","trash105.jpg  trash126.jpg  trash22.jpg  trash43.jpg  trash64.jpg  trash85.jpg\n","trash106.jpg  trash127.jpg  trash23.jpg  trash44.jpg  trash65.jpg  trash86.jpg\n","trash107.jpg  trash128.jpg  trash24.jpg  trash45.jpg  trash66.jpg  trash87.jpg\n","trash108.jpg  trash129.jpg  trash25.jpg  trash46.jpg  trash67.jpg  trash88.jpg\n","trash109.jpg  trash12.jpg   trash26.jpg  trash47.jpg  trash68.jpg  trash89.jpg\n","trash10.jpg   trash130.jpg  trash27.jpg  trash48.jpg  trash69.jpg  trash8.jpg\n","trash110.jpg  trash131.jpg  trash28.jpg  trash49.jpg  trash6.jpg   trash90.jpg\n","trash111.jpg  trash132.jpg  trash29.jpg  trash4.jpg   trash70.jpg  trash91.jpg\n","trash112.jpg  trash133.jpg  trash2.jpg\t trash50.jpg  trash71.jpg  trash92.jpg\n","trash113.jpg  trash134.jpg  trash30.jpg  trash51.jpg  trash72.jpg  trash93.jpg\n","trash114.jpg  trash135.jpg  trash31.jpg  trash52.jpg  trash73.jpg  trash94.jpg\n","trash115.jpg  trash136.jpg  trash32.jpg  trash53.jpg  trash74.jpg  trash95.jpg\n","trash116.jpg  trash137.jpg  trash33.jpg  trash54.jpg  trash75.jpg  trash96.jpg\n","trash117.jpg  trash13.jpg   trash34.jpg  trash55.jpg  trash76.jpg  trash97.jpg\n","trash118.jpg  trash14.jpg   trash35.jpg  trash56.jpg  trash77.jpg  trash98.jpg\n","trash119.jpg  trash15.jpg   trash36.jpg  trash57.jpg  trash78.jpg  trash99.jpg\n","trash11.jpg   trash16.jpg   trash37.jpg  trash58.jpg  trash79.jpg  trash9.jpg\n","trash120.jpg  trash17.jpg   trash38.jpg  trash59.jpg  trash7.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vK4hhHg0FNiC","colab_type":"code","colab":{}},"source":["!shuf -n 101 -e dataset-original/glass/* | xargs -i mv {} dataset-validation/glass/\n","!shuf -n 144 -e dataset-original/paper/* | xargs -i mv {} dataset-validation/paper/\n","!shuf -n 53 -e dataset-original/cardboard/* | xargs -i mv {} dataset-validation/cardboard/\n","!shuf -n 82 -e dataset-original/plastic/* | xargs -i mv {} dataset-validation/plastic/\n","!shuf -n 60 -e dataset-original/metal/* | xargs -i mv {} dataset-validation/metal/\n","!shuf -n 37 -e dataset-original/trash/* | xargs -i mv {} dataset-validation/trash/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uFV1fTT9HspD","colab_type":"code","outputId":"97b2fb92-2491-4160-f60d-7551cd940a00","executionInfo":{"status":"ok","timestamp":1574969493037,"user_tz":480,"elapsed":110974,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!ls dataset-original/glass | wc -l\n","!ls dataset-validation/glass | wc -l"],"execution_count":5,"outputs":[{"output_type":"stream","text":["400\n","101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VCMDyL_T7fdA","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torch.nn as nn\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6wBY7KQYiTN","colab_type":"code","colab":{}},"source":["transformationsTrain = transforms.Compose([transforms.Resize(255), transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n","                                           transforms.RandomRotation(degrees = (90, -90)), transforms.ToTensor(), \n","                                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","transformationsValidation = transforms.Compose([transforms.Resize(255), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDud-z_t-7QK","colab_type":"code","colab":{}},"source":["train_set = datasets.ImageFolder(\"dataset-original\", transform = transformationsTrain)\n","val_set = datasets.ImageFolder(\"dataset-validation\", transform = transformationsValidation)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICFzgBLtdiwC","colab_type":"code","colab":{}},"source":["train_loader = torch.utils.data.DataLoader(train_set, batch_size=50, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size =50, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3TUtmB4LheG","colab_type":"code","outputId":"9c23c9a1-01e2-49c2-ce17-0fd8833c30ee","executionInfo":{"status":"ok","timestamp":1574873217894,"user_tz":480,"elapsed":112439,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = torchvision.models.resnet34(pretrained=True)\n","model.cuda()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n","100%|██████████| 83.3M/83.3M [00:05<00:00, 15.4MB/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (4): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (5): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"SWIqG7BNLuXi","colab_type":"code","colab":{}},"source":["learningRate = 1e-3\n","epochs = 10\n","minibatches = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aebz65-wCYWl","colab_type":"code","outputId":"1496cdda-001c-4bf7-c75c-f0541697c4ff","executionInfo":{"status":"ok","timestamp":1574873272400,"user_tz":480,"elapsed":4892,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["!pip install adabound\n","import adabound"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting adabound\n","  Downloading https://files.pythonhosted.org/packages/cd/44/0c2c414effb3d9750d780b230dbb67ea48ddc5d9a6d7a9b7e6fcc6bdcff9/adabound-0.0.5-py3-none-any.whl\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from adabound) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->adabound) (1.17.4)\n","Installing collected packages: adabound\n","Successfully installed adabound-0.0.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EjMPAuiVCVTm","colab_type":"code","outputId":"f4d88c93-8bfd-4ff3-b2b6-5bb83ac1e9f9","executionInfo":{"status":"ok","timestamp":1574879609891,"user_tz":480,"elapsed":6320793,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n","\n","train_losses, train_accs = [], []\n","val_losses, val_accs = [], []\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    model.train()\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = outputs.data.max(1)[1]\n","        matches = labels == pred\n","        accuracy = matches.float().mean()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % minibatches == minibatches - 1:    # print every n mini-batches\n","            print('[%d, %5d] loss: %.3f accuracy: %.3f itemLoss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / minibatches, accuracy, loss.item()))\n","            running_loss = 0.0\n","\n","        train_losses.append(loss.item())\n","        train_accs.append(accuracy.item())\n","    \n","    model.eval()\n","    val_loss, correct = 0., 0\n","    total = 0\n","    with torch.no_grad():\n","      for data in val_loader:\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        outputs = model(inputs)\n","        val_loss += criterion(outputs, labels).item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the validation images: %d %%' % (\n","    100 * correct / total))\n","\n","    val_loss /= len(val_loader)\n","    acc = correct / len(val_loader)\n","\n","    val_losses.append(val_loss)\n","    val_accs.append(acc)\n","\n","print('Finished Training')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[1,     5] loss: 4.667 accuracy: 0.560 itemLoss: 2.256\n","[1,    10] loss: 1.589 accuracy: 0.560 itemLoss: 1.666\n","[1,    15] loss: 1.290 accuracy: 0.400 itemLoss: 1.242\n","[1,    20] loss: 1.277 accuracy: 0.480 itemLoss: 1.211\n","[1,    25] loss: 1.184 accuracy: 0.680 itemLoss: 1.048\n","[1,    30] loss: 1.004 accuracy: 0.600 itemLoss: 1.112\n","[1,    35] loss: 0.935 accuracy: 0.700 itemLoss: 0.814\n","[1,    40] loss: 0.898 accuracy: 0.660 itemLoss: 0.802\n","Accuracy of the network on the validation images: 51 %\n","[2,     5] loss: 0.783 accuracy: 0.720 itemLoss: 0.839\n","[2,    10] loss: 0.829 accuracy: 0.680 itemLoss: 0.968\n","[2,    15] loss: 0.715 accuracy: 0.760 itemLoss: 0.749\n","[2,    20] loss: 0.890 accuracy: 0.700 itemLoss: 0.816\n","[2,    25] loss: 0.818 accuracy: 0.760 itemLoss: 0.601\n","[2,    30] loss: 0.733 accuracy: 0.760 itemLoss: 0.684\n","[2,    35] loss: 1.074 accuracy: 0.660 itemLoss: 0.864\n","[2,    40] loss: 0.845 accuracy: 0.700 itemLoss: 0.793\n","Accuracy of the network on the validation images: 39 %\n","[3,     5] loss: 0.847 accuracy: 0.780 itemLoss: 0.606\n","[3,    10] loss: 0.717 accuracy: 0.720 itemLoss: 0.745\n","[3,    15] loss: 0.704 accuracy: 0.680 itemLoss: 0.877\n","[3,    20] loss: 0.631 accuracy: 0.740 itemLoss: 0.678\n","[3,    25] loss: 0.716 accuracy: 0.740 itemLoss: 0.658\n","[3,    30] loss: 0.642 accuracy: 0.840 itemLoss: 0.552\n","[3,    35] loss: 0.613 accuracy: 0.820 itemLoss: 0.692\n","[3,    40] loss: 0.646 accuracy: 0.680 itemLoss: 0.773\n","Accuracy of the network on the validation images: 62 %\n","[4,     5] loss: 0.504 accuracy: 0.720 itemLoss: 0.661\n","[4,    10] loss: 0.407 accuracy: 0.760 itemLoss: 0.603\n","[4,    15] loss: 0.568 accuracy: 0.820 itemLoss: 0.566\n","[4,    20] loss: 0.623 accuracy: 0.720 itemLoss: 0.840\n","[4,    25] loss: 0.510 accuracy: 0.780 itemLoss: 0.588\n","[4,    30] loss: 0.444 accuracy: 0.900 itemLoss: 0.374\n","[4,    35] loss: 0.471 accuracy: 0.920 itemLoss: 0.296\n","[4,    40] loss: 0.551 accuracy: 0.780 itemLoss: 0.640\n","Accuracy of the network on the validation images: 70 %\n","[5,     5] loss: 0.491 accuracy: 0.820 itemLoss: 0.467\n","[5,    10] loss: 0.488 accuracy: 0.840 itemLoss: 0.460\n","[5,    15] loss: 0.369 accuracy: 0.780 itemLoss: 0.478\n","[5,    20] loss: 0.434 accuracy: 0.860 itemLoss: 0.416\n","[5,    25] loss: 0.370 accuracy: 0.820 itemLoss: 0.386\n","[5,    30] loss: 0.481 accuracy: 0.800 itemLoss: 0.539\n","[5,    35] loss: 0.457 accuracy: 0.860 itemLoss: 0.338\n","[5,    40] loss: 0.391 accuracy: 0.860 itemLoss: 0.349\n","Accuracy of the network on the validation images: 77 %\n","[6,     5] loss: 0.336 accuracy: 0.840 itemLoss: 0.415\n","[6,    10] loss: 0.378 accuracy: 0.880 itemLoss: 0.385\n","[6,    15] loss: 0.509 accuracy: 0.800 itemLoss: 0.621\n","[6,    20] loss: 0.551 accuracy: 0.780 itemLoss: 0.616\n","[6,    25] loss: 0.364 accuracy: 0.940 itemLoss: 0.324\n","[6,    30] loss: 0.420 accuracy: 0.900 itemLoss: 0.323\n","[6,    35] loss: 0.322 accuracy: 0.960 itemLoss: 0.249\n","[6,    40] loss: 0.371 accuracy: 0.900 itemLoss: 0.244\n","Accuracy of the network on the validation images: 82 %\n","[7,     5] loss: 0.290 accuracy: 0.900 itemLoss: 0.314\n","[7,    10] loss: 0.400 accuracy: 0.880 itemLoss: 0.315\n","[7,    15] loss: 0.342 accuracy: 0.900 itemLoss: 0.275\n","[7,    20] loss: 0.327 accuracy: 0.940 itemLoss: 0.261\n","[7,    25] loss: 0.335 accuracy: 0.920 itemLoss: 0.325\n","[7,    30] loss: 0.346 accuracy: 0.840 itemLoss: 0.445\n","[7,    35] loss: 0.317 accuracy: 0.900 itemLoss: 0.299\n","[7,    40] loss: 0.338 accuracy: 0.900 itemLoss: 0.260\n","Accuracy of the network on the validation images: 85 %\n","[8,     5] loss: 0.258 accuracy: 0.900 itemLoss: 0.292\n","[8,    10] loss: 0.311 accuracy: 0.900 itemLoss: 0.326\n","[8,    15] loss: 0.362 accuracy: 0.880 itemLoss: 0.274\n","[8,    20] loss: 0.380 accuracy: 0.860 itemLoss: 0.424\n","[8,    25] loss: 0.314 accuracy: 0.920 itemLoss: 0.336\n","[8,    30] loss: 0.266 accuracy: 0.920 itemLoss: 0.359\n","[8,    35] loss: 0.343 accuracy: 0.940 itemLoss: 0.197\n","[8,    40] loss: 0.318 accuracy: 0.940 itemLoss: 0.202\n","Accuracy of the network on the validation images: 85 %\n","[9,     5] loss: 0.299 accuracy: 0.920 itemLoss: 0.306\n","[9,    10] loss: 0.235 accuracy: 0.920 itemLoss: 0.229\n","[9,    15] loss: 0.223 accuracy: 0.940 itemLoss: 0.174\n","[9,    20] loss: 0.178 accuracy: 0.940 itemLoss: 0.097\n","[9,    25] loss: 0.217 accuracy: 0.960 itemLoss: 0.138\n","[9,    30] loss: 0.275 accuracy: 0.880 itemLoss: 0.267\n","[9,    35] loss: 0.268 accuracy: 0.900 itemLoss: 0.337\n","[9,    40] loss: 0.310 accuracy: 0.920 itemLoss: 0.397\n","Accuracy of the network on the validation images: 79 %\n","[10,     5] loss: 0.183 accuracy: 0.940 itemLoss: 0.235\n","[10,    10] loss: 0.297 accuracy: 0.980 itemLoss: 0.121\n","[10,    15] loss: 0.288 accuracy: 0.880 itemLoss: 0.254\n","[10,    20] loss: 0.216 accuracy: 0.920 itemLoss: 0.259\n","[10,    25] loss: 0.355 accuracy: 0.940 itemLoss: 0.225\n","[10,    30] loss: 0.269 accuracy: 0.800 itemLoss: 0.558\n","[10,    35] loss: 0.206 accuracy: 0.920 itemLoss: 0.273\n","[10,    40] loss: 0.291 accuracy: 0.940 itemLoss: 0.169\n","Accuracy of the network on the validation images: 87 %\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-MjJabJTJ5Tq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2848ba5c-ad42-4824-9a58-81ab0c8cd22c","executionInfo":{"status":"ok","timestamp":1574886235922,"user_tz":480,"elapsed":3274709,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}}},"source":["model = torchvision.models.resnet34(pretrained=True)\n","model.cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","train_losses, train_accs = [], []\n","val_losses, val_accs = [], []\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    model.train()\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = outputs.data.max(1)[1]\n","        matches = labels == pred\n","        accuracy = matches.float().mean()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % minibatches == minibatches - 1:    # print every n mini-batches\n","            print('[%d, %5d] loss: %.3f accuracy: %.3f itemLoss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / minibatches, accuracy, loss.item()))\n","            running_loss = 0.0\n","\n","        train_losses.append(loss.item())\n","        train_accs.append(accuracy.item())\n","    \n","    model.eval()\n","    val_loss, correct = 0., 0\n","    total = 0\n","    with torch.no_grad():\n","      for data in val_loader:\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        outputs = model(inputs)\n","        val_loss += criterion(outputs, labels).item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the validation images: %d %%' % (\n","    100 * correct / total))\n","\n","    val_loss /= len(val_loader)\n","    acc = correct / len(val_loader)\n","\n","    val_losses.append(val_loss)\n","    val_accs.append(acc)\n","\n","print('Finished Training')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[1,     5] loss: 5.407 accuracy: 0.500 itemLoss: 3.394\n","[1,    10] loss: 1.652 accuracy: 0.600 itemLoss: 1.431\n","[1,    15] loss: 1.219 accuracy: 0.500 itemLoss: 1.239\n","[1,    20] loss: 1.179 accuracy: 0.640 itemLoss: 1.107\n","[1,    25] loss: 1.195 accuracy: 0.680 itemLoss: 1.096\n","[1,    30] loss: 1.057 accuracy: 0.600 itemLoss: 1.069\n","[1,    35] loss: 0.878 accuracy: 0.660 itemLoss: 0.832\n","[1,    40] loss: 1.069 accuracy: 0.540 itemLoss: 1.090\n","Accuracy of the network on the validation images: 62 %\n","[2,     5] loss: 1.010 accuracy: 0.580 itemLoss: 1.027\n","[2,    10] loss: 0.934 accuracy: 0.660 itemLoss: 0.964\n","[2,    15] loss: 0.750 accuracy: 0.640 itemLoss: 0.959\n","[2,    20] loss: 0.744 accuracy: 0.620 itemLoss: 1.030\n","[2,    25] loss: 0.777 accuracy: 0.700 itemLoss: 0.739\n","[2,    30] loss: 0.833 accuracy: 0.680 itemLoss: 1.008\n","[2,    35] loss: 0.679 accuracy: 0.700 itemLoss: 0.760\n","[2,    40] loss: 0.644 accuracy: 0.820 itemLoss: 0.607\n","Accuracy of the network on the validation images: 65 %\n","[3,     5] loss: 0.660 accuracy: 0.740 itemLoss: 0.571\n","[3,    10] loss: 0.622 accuracy: 0.820 itemLoss: 0.477\n","[3,    15] loss: 0.640 accuracy: 0.720 itemLoss: 0.714\n","[3,    20] loss: 0.576 accuracy: 0.860 itemLoss: 0.563\n","[3,    25] loss: 0.649 accuracy: 0.780 itemLoss: 0.652\n","[3,    30] loss: 0.578 accuracy: 0.840 itemLoss: 0.443\n","[3,    35] loss: 0.576 accuracy: 0.820 itemLoss: 0.527\n","[3,    40] loss: 0.583 accuracy: 0.760 itemLoss: 0.644\n","Accuracy of the network on the validation images: 73 %\n","[4,     5] loss: 0.595 accuracy: 0.780 itemLoss: 0.513\n","[4,    10] loss: 0.595 accuracy: 0.740 itemLoss: 0.874\n","[4,    15] loss: 0.659 accuracy: 0.780 itemLoss: 0.761\n","[4,    20] loss: 0.622 accuracy: 0.820 itemLoss: 0.460\n","[4,    25] loss: 0.502 accuracy: 0.700 itemLoss: 0.639\n","[4,    30] loss: 0.556 accuracy: 0.760 itemLoss: 0.569\n","[4,    35] loss: 0.508 accuracy: 0.860 itemLoss: 0.427\n","[4,    40] loss: 0.503 accuracy: 0.860 itemLoss: 0.347\n","Accuracy of the network on the validation images: 51 %\n","[5,     5] loss: 0.431 accuracy: 0.920 itemLoss: 0.350\n","[5,    10] loss: 0.587 accuracy: 0.920 itemLoss: 0.389\n","[5,    15] loss: 0.638 accuracy: 0.740 itemLoss: 0.819\n","[5,    20] loss: 0.616 accuracy: 0.800 itemLoss: 0.525\n","[5,    25] loss: 0.632 accuracy: 0.780 itemLoss: 0.594\n","[5,    30] loss: 0.551 accuracy: 0.880 itemLoss: 0.386\n","[5,    35] loss: 0.485 accuracy: 0.800 itemLoss: 0.529\n","[5,    40] loss: 0.568 accuracy: 0.880 itemLoss: 0.523\n","Accuracy of the network on the validation images: 71 %\n","[6,     5] loss: 0.482 accuracy: 0.860 itemLoss: 0.304\n","[6,    10] loss: 0.378 accuracy: 0.960 itemLoss: 0.245\n","[6,    15] loss: 0.462 accuracy: 0.880 itemLoss: 0.400\n","[6,    20] loss: 0.371 accuracy: 0.920 itemLoss: 0.253\n","[6,    25] loss: 0.578 accuracy: 0.780 itemLoss: 0.826\n","[6,    30] loss: 0.471 accuracy: 0.880 itemLoss: 0.333\n","[6,    35] loss: 0.539 accuracy: 0.800 itemLoss: 0.745\n","[6,    40] loss: 0.534 accuracy: 0.820 itemLoss: 0.563\n","Accuracy of the network on the validation images: 75 %\n","[7,     5] loss: 0.456 accuracy: 0.920 itemLoss: 0.383\n","[7,    10] loss: 0.343 accuracy: 0.880 itemLoss: 0.351\n","[7,    15] loss: 0.383 accuracy: 0.900 itemLoss: 0.247\n","[7,    20] loss: 0.405 accuracy: 0.880 itemLoss: 0.328\n","[7,    25] loss: 0.477 accuracy: 0.900 itemLoss: 0.381\n","[7,    30] loss: 0.486 accuracy: 0.740 itemLoss: 0.865\n","[7,    35] loss: 0.419 accuracy: 0.900 itemLoss: 0.312\n","[7,    40] loss: 0.513 accuracy: 0.800 itemLoss: 0.490\n","Accuracy of the network on the validation images: 82 %\n","[8,     5] loss: 0.456 accuracy: 0.900 itemLoss: 0.411\n","[8,    10] loss: 0.462 accuracy: 0.720 itemLoss: 0.812\n","[8,    15] loss: 0.374 accuracy: 0.820 itemLoss: 0.394\n","[8,    20] loss: 0.416 accuracy: 0.880 itemLoss: 0.364\n","[8,    25] loss: 0.334 accuracy: 0.920 itemLoss: 0.209\n","[8,    30] loss: 0.497 accuracy: 0.860 itemLoss: 0.302\n","[8,    35] loss: 0.428 accuracy: 0.880 itemLoss: 0.370\n","[8,    40] loss: 0.332 accuracy: 0.940 itemLoss: 0.261\n","Accuracy of the network on the validation images: 80 %\n","[9,     5] loss: 0.369 accuracy: 0.900 itemLoss: 0.257\n","[9,    10] loss: 0.321 accuracy: 0.860 itemLoss: 0.273\n","[9,    15] loss: 0.410 accuracy: 0.940 itemLoss: 0.199\n","[9,    20] loss: 0.325 accuracy: 0.940 itemLoss: 0.169\n","[9,    25] loss: 0.352 accuracy: 0.920 itemLoss: 0.222\n","[9,    30] loss: 0.290 accuracy: 0.900 itemLoss: 0.273\n","[9,    35] loss: 0.420 accuracy: 0.780 itemLoss: 0.601\n","[9,    40] loss: 0.497 accuracy: 0.820 itemLoss: 0.542\n","Accuracy of the network on the validation images: 72 %\n","[10,     5] loss: 0.269 accuracy: 0.940 itemLoss: 0.181\n","[10,    10] loss: 0.377 accuracy: 0.880 itemLoss: 0.359\n","[10,    15] loss: 0.440 accuracy: 0.860 itemLoss: 0.652\n","[10,    20] loss: 0.426 accuracy: 0.820 itemLoss: 0.429\n","[10,    25] loss: 0.359 accuracy: 0.780 itemLoss: 0.609\n","[10,    30] loss: 0.426 accuracy: 0.900 itemLoss: 0.335\n","[10,    35] loss: 0.371 accuracy: 0.940 itemLoss: 0.249\n","[10,    40] loss: 0.378 accuracy: 0.820 itemLoss: 0.595\n","Accuracy of the network on the validation images: 75 %\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i7OGz4Cob8Gy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":385},"outputId":"3d731580-d96d-4596-96d5-6a44c5bcf621","executionInfo":{"status":"error","timestamp":1574969711006,"user_tz":480,"elapsed":14511,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}}},"source":["torch.cuda.empty_cache()\n","\n","model = torchvision.models.resnet152(pretrained=True)\n","model.cuda()\n","\n","minibatches = 5\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n","\n","train_losses, train_accs = [], []\n","val_losses, val_accs = [], []\n","\n","for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    model.train()\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = outputs.data.max(1)[1]\n","        matches = labels == pred\n","        accuracy = matches.float().mean()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % minibatches == minibatches - 1:    # print every n mini-batches\n","            print('[%d, %5d] loss: %.3f accuracy: %.3f itemLoss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / minibatches, accuracy, loss.item()))\n","            running_loss = 0.0\n","\n","        train_losses.append(loss.item())\n","        train_accs.append(accuracy.item())\n","    \n","    model.eval()\n","    val_loss, correct = 0., 0\n","    total = 0\n","    with torch.no_grad():\n","      for data in val_loader:\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        outputs = model(inputs)\n","        val_loss += criterion(outputs, labels).item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the validation images: %f %%' % (\n","    100 * correct / total))\n","\n","    val_loss /= len(val_loader)\n","    acc = correct / len(val_loader)\n","\n","    val_losses.append(val_loss)\n","    val_accs.append(acc)\n","\n","print('Finished Training')"],"execution_count":13,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d6ac8a28f3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 15.90 GiB total capacity; 14.47 GiB already allocated; 43.88 MiB free; 700.86 MiB cached)"]}]},{"cell_type":"code","metadata":{"id":"XCDAfefmeZlL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":420},"outputId":"92dbaa97-5c08-4a0b-bf07-2b994b238604","executionInfo":{"status":"error","timestamp":1574969521844,"user_tz":480,"elapsed":4192,"user":{"displayName":"Khanh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhmdzYE4Np2rwuKzC_ZuN37tvzMf_2DpvMfuRD=s64","userId":"04394352403186034085"}}},"source":["model = torchvision.models.densenet161(pretrained=True)\n","model.cuda()\n","\n","minibatches = 5\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n","\n","train_losses, train_accs = [], []\n","val_losses, val_accs = [], []\n","\n","for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    model.train()\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = outputs.data.max(1)[1]\n","        matches = labels == pred\n","        accuracy = matches.float().mean()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % minibatches == minibatches - 1:    # print every n mini-batches\n","            print('[%d, %5d] loss: %.3f accuracy: %.3f itemLoss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / minibatches, accuracy, loss.item()))\n","            running_loss = 0.0\n","\n","        train_losses.append(loss.item())\n","        train_accs.append(accuracy.item())\n","    \n","    model.eval()\n","    val_loss, correct = 0., 0\n","    total = 0\n","    with torch.no_grad():\n","      for data in val_loader:\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        outputs = model(inputs)\n","        val_loss += criterion(outputs, labels).item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the validation images: %f %%' % (\n","    100 * correct / total))\n","\n","    val_loss /= len(val_loader)\n","    acc = correct / len(val_loader)\n","\n","    val_losses.append(val_loss)\n","    val_accs.append(acc)\n","\n","print('Finished Training')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/checkpoints/densenet161-8d451a50.pth\n","100%|██████████| 110M/110M [00:02<00:00, 48.6MB/s]\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-bd86e9c7c3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdensenet161\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mminibatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 14.58 GiB already allocated; 1.88 MiB free; 637.96 MiB cached)"]}]},{"cell_type":"code","metadata":{"id":"lIH08Y_lfpcO","colab_type":"code","colab":{}},"source":["model = torchvision.models.inception_v3(pretrained=True)\n","model.cuda()\n","\n","minibatches = 5\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n","\n","train_losses, train_accs = [], []\n","val_losses, val_accs = [], []\n","\n","for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    model.train()\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = outputs.data.max(1)[1]\n","        matches = labels == pred\n","        accuracy = matches.float().mean()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % minibatches == minibatches - 1:    # print every n mini-batches\n","            print('[%d, %5d] loss: %.3f accuracy: %.3f itemLoss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / minibatches, accuracy, loss.item()))\n","            running_loss = 0.0\n","\n","        train_losses.append(loss.item())\n","        train_accs.append(accuracy.item())\n","    \n","    model.eval()\n","    val_loss, correct = 0., 0\n","    total = 0\n","    with torch.no_grad():\n","      for data in val_loader:\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        outputs = model(inputs)\n","        val_loss += criterion(outputs, labels).item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the validation images: %f %%' % (\n","    100 * correct / total))\n","\n","    val_loss /= len(val_loader)\n","    acc = correct / len(val_loader)\n","\n","    val_losses.append(val_loss)\n","    val_accs.append(acc)\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[]}]}